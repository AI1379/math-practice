{
  "cells": [
    {
      "cell_type": "raw",
      "id": "62d3e682",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"Homework 3: The Death and Life of Great American City Scaling Laws\"\n",
        "output: pdf_document\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d445f0a",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "**Background**: In the previous lectures and lab, we fitted the following model\n",
        "$$\n",
        " Y = y_0 N^a + \\mathrm{noise}\n",
        "$$\n",
        "by minimizing the mean squared error\n",
        "$$\n",
        " \\frac{1}{n}\\sum_{i=1}^{n}{(Y_i - y_0 N_i^a)^2}.\n",
        "$$\n",
        "\n",
        "We did this by approximating the derivative of the MSE, and adjusting $a$ by an amount proportional to that, stopping when the derivative became small.  Our procedure assumed we knew $y_0$.  In this assignment, we will use a built-in R function to estimate both parameters at once; it uses a fancier version of the same idea.\n",
        "\n",
        "Because the model is nonlinear, there is no simple formula for the parameter estimates in terms of the data.  Also unlike linear models, there is no simple formula for the _standard errors_ of the parameter estimates.  We will therefore use a technique called **the jackknife** to get approximate standard errors.\n",
        "\n",
        "Here is how the jackknife works:\n",
        "\n",
        "* Get a set of $n$ data points and get an estimate $\\hat{\\theta}$ for the  parameter of interest $\\theta$.\n",
        "* For each data point $i$, remove $i$ from the data set, and get an  estimate $\\hat{\\theta}_{(-i)}$ from the remaining $n-1$ data points.  The $\\hat{\\theta}_{(-i)}$ are sometimes called the \"jackknife estimates\".\n",
        "* Find the mean $\\overline{\\theta}$ of the $n$ values of $\\hat{\\theta}_{(-i)}$\n",
        "* The jackknife variance of $\\hat{\\theta}$ is\n",
        "  $$\n",
        "  \\frac{n-1}{n}\\sum_{i=1}^{n}{(\\hat{\\theta}_{(-i)} - \\overline{\\theta})^2} = \\frac{(n-1)^2}{n}\\mathrm{var}{[\\hat{\\theta}_{(-i)}]}\n",
        "  $$\n",
        "where $\\mathrm{var}$ stands for the sample variance.  (_Challenge_: can you explain the factor of $(n-1)^2/n$?  _Hint_: think about what happens when $n$ is large so $(n-1)/n \\approx 1$.)\n",
        "* The jackknife standard error of $\\hat{\\theta}$ is the square root of the jackknife variance.\n",
        "  \n",
        "You will estimate the power-law scaling model, and its uncertainty, using the data alluded to in lecture, available in the file `gmp.dat` from lecture, which contains data for 2006.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "bad1e670",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(ggplot2)\n",
        "options(warn = -1)\n",
        "\n",
        "gmp <- read.table(\"data/gmp.dat\")\n",
        "gmp$pop <- round(gmp$gmp / gmp$pcgmp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10eb2f27",
      "metadata": {},
      "source": [
        "\n",
        "1. First, plot the data as in lecture, with per capita GMP on the y-axis and population on the x-axis. Add the curve function with the default values provided in lecture. Add two more curves corresponding to $a=0.1$ and $a=0.15$; use the `col` option to give each curve a different color (of your choice).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "6565dc83",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 420,
              "width": 420
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_plot <- ggplot(gmp, aes(x = pop, y = pcgmp)) +\n",
        "    geom_point(alpha = 0.6, size = 2) +\n",
        "    scale_x_log10(labels = scales::comma) +\n",
        "    scale_y_log10(labels = scales::dollar) +\n",
        "    labs(\n",
        "        x = \"Population (log scale)\",\n",
        "        y = \"Per Capita GMP (USD)\",\n",
        "        title = \"Power-law Scaling of City Productivity\"\n",
        "    ) +\n",
        "    theme_minimal(base_size = 12)\n",
        "\n",
        "final_plot <- base_plot +\n",
        "    stat_function(\n",
        "        fun = function(x) 6611 * x^(1 / 8),\n",
        "        aes(color = \"a = 0.125 (Default)\"),\n",
        "        linewidth = 1.2\n",
        "    ) +\n",
        "    stat_function(\n",
        "        fun = function(x) 6611 * x^0.1,\n",
        "        aes(color = \"a = 0.10\"),\n",
        "        linewidth = 1.2\n",
        "    ) +\n",
        "    stat_function(\n",
        "        fun = function(x) 6611 * x^0.15,\n",
        "        aes(color = \"a = 0.15\"),\n",
        "        linewidth = 1.2\n",
        "    ) +\n",
        "    scale_color_manual(\n",
        "        name = \"Theoretical Curves\",\n",
        "        values = c(\n",
        "            \"a = 0.125 (Default)\" = \"red\",\n",
        "            \"a = 0.10\" = \"blue\",\n",
        "            \"a = 0.15\" = \"green\"\n",
        "        )\n",
        "    ) +\n",
        "    theme(\n",
        "        legend.position = c(0.8, 0.2),\n",
        "        legend.background = element_rect(fill = \"white\", color = \"grey50\")\n",
        "    )\n",
        "\n",
        "final_plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ae9348",
      "metadata": {},
      "source": [
        "\n",
        "2. Write a function, called `mse()`, which calculates the mean squared error of the model on a given data set. `mse()` should take three arguments: a numeric vector of length two, the first component standing for $y_0$ and the second for $a$; a numerical vector containing the values of $N$; and a numerical vector containing the values of $Y$.  The function should return a single numerical value. The latter two arguments should have as the default values the columns `pop` and `pcgmp` (respectively) from the `gmp` data frame from lecture.  Your function may not use `for()` or any other loop. Check that, with the default data, you get the following values.\n",
        "```r\n",
        "> mse(c(6611,0.15))\n",
        "[1] 207057513\n",
        "> mse(c(5000,0.10))\n",
        "[1] 298459915\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "01051f41",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "207057512.651299"
            ],
            "text/latex": [
              "207057512.651299"
            ],
            "text/markdown": [
              "207057512.651299"
            ],
            "text/plain": [
              "[1] 207057513"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "298459913.954928"
            ],
            "text/latex": [
              "298459913.954928"
            ],
            "text/markdown": [
              "298459913.954928"
            ],
            "text/plain": [
              "[1] 298459914"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mse <- function(iv, n = gmp$pop, y = gmp$pcgmp) {\n",
        "    y0 <- iv[1]\n",
        "    a <- iv[2]\n",
        "    y_hat <- y0 * n^a\n",
        "    return(mean((y - y_hat)^2))\n",
        "}\n",
        "\n",
        "mse(c(6611, 0.15))\n",
        "\n",
        "mse(c(5000, 0.10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e17757d",
      "metadata": {},
      "source": [
        "\n",
        "3. R has several built-in functions for optimization, which we will meet as we go through the course.  One of the simplest is `nlm()`, or non-linear minimization. `nlm()` takes two required arguments: a function, and a starting value for that function. Run `nlm()` three times with your function `mse()` and three starting value pairs for $y0$ and $a$ as in\n",
        "```r\n",
        "nlm(mse, c(y0=6611,a=1/8))\n",
        "```\n",
        "What do the quantities `minimum` and `estimate` represent? What values does it return for these?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "1ca32f19",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$minimum</dt>\n",
              "\t\t<dd>61857059.8727315</dd>\n",
              "\t<dt>$estimate</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>6611.00000001484</li><li>0.126317722842728</li></ol>\n",
              "</dd>\n",
              "\t<dt>$gradient</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>50.0486389696241</li><li>-9.98377799987793</li></ol>\n",
              "</dd>\n",
              "\t<dt>$code</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>$iterations</dt>\n",
              "\t\t<dd>3</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$minimum] 61857059.8727315\n",
              "\\item[\\$estimate] \\begin{enumerate*}\n",
              "\\item 6611.00000001484\n",
              "\\item 0.126317722842728\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$gradient] \\begin{enumerate*}\n",
              "\\item 50.0486389696241\n",
              "\\item -9.98377799987793\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$code] 2\n",
              "\\item[\\$iterations] 3\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$minimum\n",
              ":   61857059.8727315\n",
              "$estimate\n",
              ":   1. 6611.00000001484\n",
              "2. 0.126317722842728\n",
              "\n",
              "\n",
              "\n",
              "$gradient\n",
              ":   1. 50.0486389696241\n",
              "2. -9.98377799987793\n",
              "\n",
              "\n",
              "\n",
              "$code\n",
              ":   2\n",
              "$iterations\n",
              ":   3\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$minimum\n",
              "[1] 61857060\n",
              "\n",
              "$estimate\n",
              "[1] 6611.0000000    0.1263177\n",
              "\n",
              "$gradient\n",
              "[1] 50.048639 -9.983778\n",
              "\n",
              "$code\n",
              "[1] 2\n",
              "\n",
              "$iterations\n",
              "[1] 3\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$minimum</dt>\n",
              "\t\t<dd>61857059.8266112</dd>\n",
              "\t<dt>$estimate</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>6610.99999972775</li><li>0.126318156293406</li></ol>\n",
              "</dd>\n",
              "\t<dt>$gradient</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>51.7635428889388</li><li>-210.189484059811</li></ol>\n",
              "</dd>\n",
              "\t<dt>$code</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>$iterations</dt>\n",
              "\t\t<dd>7</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$minimum] 61857059.8266112\n",
              "\\item[\\$estimate] \\begin{enumerate*}\n",
              "\\item 6610.99999972775\n",
              "\\item 0.126318156293406\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$gradient] \\begin{enumerate*}\n",
              "\\item 51.7635428889388\n",
              "\\item -210.189484059811\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$code] 2\n",
              "\\item[\\$iterations] 7\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$minimum\n",
              ":   61857059.8266112\n",
              "$estimate\n",
              ":   1. 6610.99999972775\n",
              "2. 0.126318156293406\n",
              "\n",
              "\n",
              "\n",
              "$gradient\n",
              ":   1. 51.7635428889388\n",
              "2. -210.189484059811\n",
              "\n",
              "\n",
              "\n",
              "$code\n",
              ":   2\n",
              "$iterations\n",
              ":   7\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$minimum\n",
              "[1] 61857060\n",
              "\n",
              "$estimate\n",
              "[1] 6610.9999997    0.1263182\n",
              "\n",
              "$gradient\n",
              "[1]   51.76354 -210.18948\n",
              "\n",
              "$code\n",
              "[1] 2\n",
              "\n",
              "$iterations\n",
              "[1] 7\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$minimum</dt>\n",
              "\t\t<dd>62521483.5949203</dd>\n",
              "\t<dt>$estimate</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>5000.00000075672</li><li>0.147591319991501</li></ol>\n",
              "</dd>\n",
              "\t<dt>$gradient</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>-1028.22544254447</li><li>11.3876163959503</li></ol>\n",
              "</dd>\n",
              "\t<dt>$code</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>$iterations</dt>\n",
              "\t\t<dd>5</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$minimum] 62521483.5949203\n",
              "\\item[\\$estimate] \\begin{enumerate*}\n",
              "\\item 5000.00000075672\n",
              "\\item 0.147591319991501\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$gradient] \\begin{enumerate*}\n",
              "\\item -1028.22544254447\n",
              "\\item 11.3876163959503\n",
              "\\end{enumerate*}\n",
              "\n",
              "\\item[\\$code] 2\n",
              "\\item[\\$iterations] 5\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$minimum\n",
              ":   62521483.5949203\n",
              "$estimate\n",
              ":   1. 5000.00000075672\n",
              "2. 0.147591319991501\n",
              "\n",
              "\n",
              "\n",
              "$gradient\n",
              ":   1. -1028.22544254447\n",
              "2. 11.3876163959503\n",
              "\n",
              "\n",
              "\n",
              "$code\n",
              ":   2\n",
              "$iterations\n",
              ":   5\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$minimum\n",
              "[1] 62521484\n",
              "\n",
              "$estimate\n",
              "[1] 5000.0000008    0.1475913\n",
              "\n",
              "$gradient\n",
              "[1] -1028.22544    11.38762\n",
              "\n",
              "$code\n",
              "[1] 2\n",
              "\n",
              "$iterations\n",
              "[1] 5\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "nlm(mse, c(y0 = 6611, a = 0.125))\n",
        "nlm(mse, c(y0 = 6611, a = 0.15))\n",
        "nlm(mse, c(y0 = 5000, a = 0.10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7086a198",
      "metadata": {},
      "source": [
        "**Answer:**\n",
        "\n",
        "The `minimum` represents the minimum value of the function being optimized (in this case, the MSE), while `estimate` gives the estimated parameters that minimize this function. When running `nlm()` with the provided starting values, it returns the optimal values for $y_0$ and $a$ that minimize the MSE for the given data.\n",
        "\n",
        "For case `c(y0=6611, a=1/8)` and `c(y0=6611, a=0.15)`, the outputs are quite similar. However, for `c(y0=5000, a=0.10)`, the outputs differ significantly, indicating that the choice of starting values can affect the optimization results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c33a83",
      "metadata": {},
      "source": [
        "\n",
        "4. Using `nlm()`, and the `mse()` function you wrote, write a function, `plm()`, which estimates the parameters $y_0$ and $a$ of the model by minimizing the mean squared error.  It should take the following arguments: an initial guess for $y_0$; an initial guess for $a$; a vector containing the $N$ values; a vector containing the $Y$ values.  All arguments except the initial guesses should have suitable default values.  It should return a list with the following components: the final guess for $y_0$; the final guess for $a$; the final value of the MSE.  Your function must call those you wrote in earlier questions (it should not repeat their code), and the appropriate arguments to `plm()` should be passed on to them. \n",
        "What parameter estimate do you get when starting from $y_0 = 6611$ and $a = 0.15$?  From $y_0 = 5000$ and $a = 0.10$?  If these are not the same, why do they differ?  Which estimate has the lower MSE?  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "d027db08",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$y0</dt>\n",
              "\t\t<dd>6610.99999972775</dd>\n",
              "\t<dt>$a</dt>\n",
              "\t\t<dd>0.126318156293406</dd>\n",
              "\t<dt>$mse</dt>\n",
              "\t\t<dd>61857059.8266112</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$y0] 6610.99999972775\n",
              "\\item[\\$a] 0.126318156293406\n",
              "\\item[\\$mse] 61857059.8266112\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$y0\n",
              ":   6610.99999972775\n",
              "$a\n",
              ":   0.126318156293406\n",
              "$mse\n",
              ":   61857059.8266112\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$y0\n",
              "[1] 6611\n",
              "\n",
              "$a\n",
              "[1] 0.1263182\n",
              "\n",
              "$mse\n",
              "[1] 61857060\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$y0</dt>\n",
              "\t\t<dd>5000.00000075672</dd>\n",
              "\t<dt>$a</dt>\n",
              "\t\t<dd>0.147591319991501</dd>\n",
              "\t<dt>$mse</dt>\n",
              "\t\t<dd>62521483.5949203</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$y0] 5000.00000075672\n",
              "\\item[\\$a] 0.147591319991501\n",
              "\\item[\\$mse] 62521483.5949203\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$y0\n",
              ":   5000.00000075672\n",
              "$a\n",
              ":   0.147591319991501\n",
              "$mse\n",
              ":   62521483.5949203\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$y0\n",
              "[1] 5000\n",
              "\n",
              "$a\n",
              "[1] 0.1475913\n",
              "\n",
              "$mse\n",
              "[1] 62521484\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plm <- function(y0, a, n = gmp$pop, y = gmp$pcgmp) {\n",
        "    result <- nlm(mse, c(y0 = y0, a = a), n = n, y = y)\n",
        "    return(list(y0 = result$estimate[1], a = result$estimate[2], mse = result$minimum))\n",
        "}\n",
        "plm(6611, 0.15)\n",
        "plm(5000, 0.10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31c3b9ab",
      "metadata": {},
      "source": [
        "**Answer**:\n",
        "\n",
        "The `nlm()` algorithm falls into a local minimum, which is not the global minimum, leading to different estimates for the parameters. The choice of starting values can significantly affect the optimization results, especially in non-linear models like this one. \n",
        "\n",
        "When starting from $y_0 = 6611$ and $a = 0.15$, the estimates are close to the expected values, while starting from $y_0 = 5000$ and $a = 0.10$ leads to a different set of estimates. The MSE for the first case is lower than that for the second case, indicating that the first set of parameters provides a better fit to the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a783e3b3",
      "metadata": {},
      "source": [
        "\n",
        "5. _Convince yourself the jackknife can work_.\n",
        "\n",
        "    a. Calculate the mean per-capita GMP across cities, and the standard error of this mean, using the built-in functions `mean()` and `sd()`, and the formula for the standard error of the mean you learned in your intro. stats. class (or looked up on Wikipedia...).\n",
        "\n",
        "    b. Write a function which takes in an integer `i`, and calculate the mean per-capita GMP for every city _except_ city number `i`.\n",
        "\n",
        "    c. Using this function, create a vector, `jackknifed.means`, which has the mean per-capita GMP where every city is held out in turn.  (You may use a `for` loop or `sapply()`.)\n",
        "\n",
        "    d. Using the vector `jackknifed.means`, calculate the jack-knife approximation to the standard error of the mean.  How well does it match your answer from part (a)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e2423c6d",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 1 × 3</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>mean</th><th scope=col>sd</th><th scope=col>sigma</th></tr>\n",
              "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>32922.53</td><td>9219.663</td><td>481.9195</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 1 × 3\n",
              "\\begin{tabular}{lll}\n",
              " mean & sd & sigma\\\\\n",
              " <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t 32922.53 & 9219.663 & 481.9195\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 1 × 3\n",
              "\n",
              "| mean &lt;dbl&gt; | sd &lt;dbl&gt; | sigma &lt;dbl&gt; |\n",
              "|---|---|---|\n",
              "| 32922.53 | 9219.663 | 481.9195 |\n",
              "\n"
            ],
            "text/plain": [
              "  mean     sd       sigma   \n",
              "1 32922.53 9219.663 481.9195"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "481.919529734973"
            ],
            "text/latex": [
              "481.919529734973"
            ],
            "text/markdown": [
              "481.919529734973"
            ],
            "text/plain": [
              "[1] 481.9195"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "3.89241918342315e-15"
            ],
            "text/latex": [
              "3.89241918342315e-15"
            ],
            "text/markdown": [
              "3.89241918342315e-15"
            ],
            "text/plain": [
              "[1] 3.892419e-15"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mean_pcgmp <- mean(gmp$pcgmp)\n",
        "sd_pcgmp <- sd(gmp$pcgmp)\n",
        "n <- nrow(gmp)\n",
        "sigma <- sd_pcgmp / sqrt(n)\n",
        "data.frame(\n",
        "    mean = mean_pcgmp,\n",
        "    sd = sd_pcgmp,\n",
        "    sigma = sigma\n",
        ")\n",
        "\n",
        "jack_mean <- function(i, data = gmp$pcgmp) {\n",
        "    return(mean(data[-i]))\n",
        "}\n",
        "\n",
        "jackknifed.means <- sapply(seq_len(n), jack_mean)\n",
        "\n",
        "theta_bar <- mean(jackknifed.means)\n",
        "jack_var <- (n - 1) / n * sum((jackknifed.means - theta_bar)^2)\n",
        "se_jack <- sqrt(jack_var)\n",
        "\n",
        "se_jack\n",
        "abs(se_jack - sigma) / sigma\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f13596",
      "metadata": {},
      "source": [
        "\n",
        "6. Write a function, `plm.jackknife()`, to calculate jackknife standard errors for the parameters $y_0$ and $a$.  It should take the same arguments as `plm()`, and return standard errors for both parameters.  This function should call your `plm()` function repeatedly.  What standard errors do you get for the two parameters?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f6390139",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$se_y0</dt>\n",
              "\t\t<dd>1.21707564159639e-08</dd>\n",
              "\t<dt>$se_a</dt>\n",
              "\t\t<dd>0.000990457212266505</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$se\\_y0] 1.21707564159639e-08\n",
              "\\item[\\$se\\_a] 0.000990457212266505\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$se_y0\n",
              ":   1.21707564159639e-08\n",
              "$se_a\n",
              ":   0.000990457212266505\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$se_y0\n",
              "[1] 1.217076e-08\n",
              "\n",
              "$se_a\n",
              "[1] 0.0009904572\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$se_y0</dt>\n",
              "\t\t<dd>2.03389783175398e-08</dd>\n",
              "\t<dt>$se_a</dt>\n",
              "\t\t<dd>0.000997982365138492</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$se\\_y0] 2.03389783175398e-08\n",
              "\\item[\\$se\\_a] 0.000997982365138492\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$se_y0\n",
              ":   2.03389783175398e-08\n",
              "$se_a\n",
              ":   0.000997982365138492\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$se_y0\n",
              "[1] 2.033898e-08\n",
              "\n",
              "$se_a\n",
              "[1] 0.0009979824\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "jackknife_se <- function(theta_hats) {\n",
        "    n <- length(theta_hats)\n",
        "    theta_bar <- mean(theta_hats)\n",
        "\n",
        "    jack_var <- (n - 1) / n * sum((theta_hats - theta_bar)^2)\n",
        "\n",
        "    sqrt(jack_var)\n",
        "}\n",
        "\n",
        "plm.jackknife <- function(y0, a, N = gmp$pop, Y = gmp$pcgmp) {\n",
        "    n <- length(N)\n",
        "\n",
        "    jack_estimates <- matrix(NA,\n",
        "        nrow = n, ncol = 2,\n",
        "        dimnames = list(NULL, c(\"y0\", \"a\"))\n",
        "    )\n",
        "\n",
        "\n",
        "    for (i in 1:n) {\n",
        "        N_sub <- N[-i]\n",
        "        Y_sub <- Y[-i]\n",
        "\n",
        "        fit <- plm(y0, a, N_sub, Y_sub)\n",
        "\n",
        "        jack_estimates[i, \"y0\"] <- fit$y0\n",
        "        jack_estimates[i, \"a\"] <- fit$a\n",
        "    }\n",
        "\n",
        "    se_y0 <- jackknife_se(jack_estimates[, \"y0\"])\n",
        "    se_a <- jackknife_se(jack_estimates[, \"a\"])\n",
        "\n",
        "    (list(se_y0 = se_y0, se_a = se_a))\n",
        "}\n",
        "\n",
        "plm.jackknife(6611, 0.15)\n",
        "plm.jackknife(5000, 0.10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c73cfc2",
      "metadata": {},
      "source": [
        "\n",
        "7. The file `gmp-2013.dat` contains measurements for 2013.  Load it, and use `plm()` and `plm.jackknife` to estimate the parameters of the model for 2013, and their standard errors.  Have the parameters of the model changed significantly?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "d67c33c1",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$y0</dt>\n",
              "\t\t<dd>6610.99999993547</dd>\n",
              "\t<dt>$a</dt>\n",
              "\t\t<dd>0.14336878471236</dd>\n",
              "\t<dt>$mse</dt>\n",
              "\t\t<dd>135210524.492827</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$y0] 6610.99999993547\n",
              "\\item[\\$a] 0.14336878471236\n",
              "\\item[\\$mse] 135210524.492827\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$y0\n",
              ":   6610.99999993547\n",
              "$a\n",
              ":   0.14336878471236\n",
              "$mse\n",
              ":   135210524.492827\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$y0\n",
              "[1] 6611\n",
              "\n",
              "$a\n",
              "[1] 0.1433688\n",
              "\n",
              "$mse\n",
              "[1] 135210524\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$se_y0</dt>\n",
              "\t\t<dd>1.34972877742154e-08</dd>\n",
              "\t<dt>$se_a</dt>\n",
              "\t\t<dd>0.00109864979242322</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$se\\_y0] 1.34972877742154e-08\n",
              "\\item[\\$se\\_a] 0.00109864979242322\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$se_y0\n",
              ":   1.34972877742154e-08\n",
              "$se_a\n",
              ":   0.00109864979242322\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$se_y0\n",
              "[1] 1.349729e-08\n",
              "\n",
              "$se_a\n",
              "[1] 0.00109865\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$y0</dt>\n",
              "\t\t<dd>5000.00000119158</dd>\n",
              "\t<dt>$a</dt>\n",
              "\t\t<dd>0.164426974547077</dd>\n",
              "\t<dt>$mse</dt>\n",
              "\t\t<dd>139208731.023517</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$y0] 5000.00000119158\n",
              "\\item[\\$a] 0.164426974547077\n",
              "\\item[\\$mse] 139208731.023517\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$y0\n",
              ":   5000.00000119158\n",
              "$a\n",
              ":   0.164426974547077\n",
              "$mse\n",
              ":   139208731.023517\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$y0\n",
              "[1] 5000\n",
              "\n",
              "$a\n",
              "[1] 0.164427\n",
              "\n",
              "$mse\n",
              "[1] 139208731\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$se_y0</dt>\n",
              "\t\t<dd>6.24847265268916e-08</dd>\n",
              "\t<dt>$se_a</dt>\n",
              "\t\t<dd>0.00112251345167824</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$se\\_y0] 6.24847265268916e-08\n",
              "\\item[\\$se\\_a] 0.00112251345167824\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$se_y0\n",
              ":   6.24847265268916e-08\n",
              "$se_a\n",
              ":   0.00112251345167824\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$se_y0\n",
              "[1] 6.248473e-08\n",
              "\n",
              "$se_a\n",
              "[1] 0.001122513\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gmp <- read.table(\"data/gmp-2013.dat\")\n",
        "gmp$pop <- round(gmp$gmp / gmp$pcgmp)\n",
        "\n",
        "plm(6611, 0.15, gmp$pop, gmp$pcgmp)\n",
        "plm.jackknife(6611, 0.15, gmp$pop, gmp$pcgmp)\n",
        "\n",
        "plm(5000, 0.10, gmp$pop, gmp$pcgmp)\n",
        "plm.jackknife(5000, 0.10, gmp$pop, gmp$pcgmp)\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "R",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
