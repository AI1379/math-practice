{
  "cells": [
    {
      "cell_type": "raw",
      "id": "28d76a62",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Date Science with R\"\n",
        "subtitle: \"Statistical models\"\n",
        "author: \"Peng Zhang\"\n",
        "institute: \"School of Mathematical Sciences, Zhejiang University\"\n",
        "date: \"2025/06/30\"\n",
        "output:\n",
        "  xaringan::moon_reader:\n",
        "    lib_dir: libs\n",
        "    nature:\n",
        "      highlightStyle: github\n",
        "      highlightLines: true\n",
        "      countIncrementalSlides: false\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6845c44c",
      "metadata": {
        "name": "setup",
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [],
      "source": [
        "options(htmltools.dir.version = FALSE)\n",
        "# source('xaringan2pdf.R')\n",
        "# xaringan_to_pdf('Chapter6.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28cddfcf",
      "metadata": {},
      "source": [
        "### Agenda\n",
        "\n",
        "- Using data frames for statistical purposes\n",
        "- Manipulation of data into more convenient forms\n",
        "- (Re-)Introduction to linear models and the model space\n",
        "\n",
        "So You've Got A Data Frame. What can we do with it?\n",
        "\n",
        "- Plot it: examine multiple variables and distributions\n",
        "- Test it: compare groups of individuals to each other\n",
        "- Check it: does it conform to what we'd like for our needs?\n",
        "\n",
        "---\n",
        "### Test Case: Birth weight data\n",
        "\n",
        "Included in R already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66ffec7",
      "metadata": {
        "message": false,
        "out.width": "250px"
      },
      "outputs": [],
      "source": [
        "library(tidyverse)\n",
        "library(lubridate)\n",
        "library(MASS)\n",
        "data(birthwt)\n",
        "summary(birthwt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b7674b",
      "metadata": {},
      "source": [
        "---\n",
        "#### Make it readable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6341c784",
      "metadata": {},
      "outputs": [],
      "source": [
        "colnames(birthwt)\n",
        "colnames(birthwt) <- c(\"birthwt.below.2500\", \"mother.age\", \n",
        "                       \"mother.weight\", \"race\",\n",
        "                       \"mother.smokes\", \"previous.prem.labor\", \n",
        "                       \"hypertension\", \"uterine.irr\",\n",
        "                       \"physician.visits\", \"birthwt.grams\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad42c19",
      "metadata": {},
      "source": [
        "Let's make all the factors more descriptive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0428003e",
      "metadata": {},
      "outputs": [],
      "source": [
        "birthwt$race <- factor(c(\"white\", \"black\", \"other\")[birthwt$race])\n",
        "birthwt$mother.smokes <- factor(c(\"No\", \"Yes\")[birthwt$mother.smokes + 1])\n",
        "birthwt$uterine.irr <- factor(c(\"No\", \"Yes\")[birthwt$uterine.irr + 1])\n",
        "birthwt$hypertension <- factor(c(\"No\", \"Yes\")[birthwt$hypertension + 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986161a0",
      "metadata": {},
      "source": [
        "---\n",
        "### Bar plot for race"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88787d3b",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "birthwt |> ggplot(aes(x = race))+\n",
        "  geom_bar()+\n",
        "  labs(title = \"Count of Mother's Race in Springfield MA, 1986\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e7e1ad",
      "metadata": {},
      "source": [
        "---\n",
        "### Scatter plot for mother's ages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56573edf",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "birthwt |> ggplot(aes(x = 1:nrow(birthwt), y = mother.age))+\n",
        "  geom_point()+\n",
        "  labs(x = 'number', title = \"Mother's Ages in Springfield MA, 1986\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8edc7b87",
      "metadata": {},
      "source": [
        "---\n",
        "### Sorted mother's ages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12a85461",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "birthwt |> arrange(mother.age) |> ggplot(aes(x = 1:nrow(birthwt), y = mother.age))+\n",
        "  geom_point()+\n",
        "  labs(x = 'number', title = \"Mother's Ages in Springfield MA, 1986\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44ac975",
      "metadata": {},
      "source": [
        "---\n",
        "### Birth weight versus mother's ages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ecadee",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "birthwt |> ggplot(aes(x = mother.age, y = birthwt.grams))+\n",
        "  geom_point()+\n",
        "  labs(title = \"Birth Weight by Mother's Age in Springfield MA, 1986\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396548cc",
      "metadata": {},
      "source": [
        "---\n",
        "### Boxplot\n",
        "\n",
        "Let's fit some models to the data pertaining to our outcome(s) of interest. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e39f8b6",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "birthwt |> ggplot(aes(x = mother.smokes, y = birthwt.grams))+  \n",
        "  geom_boxplot()+\n",
        "  labs(title = \"Birth Weight by Mother's Smoking Habit\", y = \"Birth Weight (g)\", x=\"Mother Smokes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6b9660",
      "metadata": {},
      "source": [
        "---\n",
        "### Basic statistical testing\n",
        "\n",
        "Tough to tell! Simple two-sample t-test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364848df",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "t.test (birthwt$birthwt.grams[birthwt$mother.smokes == \"Yes\"], \n",
        "        birthwt$birthwt.grams[birthwt$mother.smokes == \"No\"], var.equal = T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "682077a6",
      "metadata": {},
      "source": [
        "---\n",
        "Does this difference match the linear model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e482a4",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "linear.model.1 <- lm (birthwt.grams ~ mother.smokes, data=birthwt)\n",
        "summary(linear.model.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef9fa77a",
      "metadata": {},
      "source": [
        "---\n",
        "### Basic statistical testing\n",
        "\n",
        "Does this difference match the linear model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69b904e",
      "metadata": {},
      "outputs": [],
      "source": [
        "linear.model.2 <- lm (birthwt.grams ~ mother.age, data=birthwt)\n",
        "summary(linear.model.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427d5b39",
      "metadata": {},
      "source": [
        "---\n",
        "Diagnostics: R tries to make it as easy as possible (but no easier). Try in R proper:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339182db",
      "metadata": {
        "dpi": 300,
        "fig.height": 9,
        "fig.width": 12,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(linear.model.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3383cc39",
      "metadata": {},
      "source": [
        "---\n",
        "### Detecting Outliers\n",
        "\n",
        "These are the default diagnostic plots for the analysis. Note that our oldest mother and her heaviest child are greatly skewing this analysis as we suspected. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ca68e3",
      "metadata": {
        "lines_to_next_cell": 0,
        "message": false
      },
      "outputs": [],
      "source": [
        "birthwt.noout <- birthwt |> filter(mother.age <= 40)\n",
        "linear.model.3 <- lm (birthwt.grams ~ mother.age, data=birthwt.noout)\n",
        "summary(linear.model.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28ad9f5",
      "metadata": {},
      "source": [
        "---\n",
        "#### More complex models\n",
        "\n",
        "Add in smoking behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1ac9b1",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "linear.model.3a <- lm (birthwt.grams ~ + mother.smokes + mother.age, data=birthwt.noout)\n",
        "summary(linear.model.3a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d471b7f",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64940542",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(linear.model.3a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3d414b",
      "metadata": {},
      "source": [
        "---\n",
        "### More complex models\n",
        "\n",
        "Add in smoking behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa071c2e",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "linear.model.3b <- lm (birthwt.grams ~ mother.age + mother.smokes + race, data=birthwt.noout)\n",
        "summary(linear.model.3b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf13830",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534e43ea",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(linear.model.3b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02978c59",
      "metadata": {},
      "source": [
        "---\n",
        "### Everything Must Go (In)\n",
        "\n",
        "Let's do a kitchen sink model on this new data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02eea605",
      "metadata": {},
      "outputs": [],
      "source": [
        "linear.model.4 <- lm (birthwt.grams ~ ., data=birthwt.noout)\n",
        "summary(linear.model.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de04e5f",
      "metadata": {},
      "source": [
        "---\n",
        "### Everything Must Go (In), Except What Must Not\n",
        "\n",
        "Whoops! One of those variables was `birthwt.below.2500` which is a function of the outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d077884e",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "linear.model.4a <- lm (birthwt.grams ~ . - birthwt.below.2500, data=birthwt.noout)\n",
        "summary(linear.model.4a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0206bb",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41574295",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(linear.model.4a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c51e2d4",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Generalized Linear Models\n",
        "\n",
        "Maybe a linear increase in birth weight is less important than if it's below a threshold like 2500 grams (5.5 pounds). Let's fit a generalized linear model instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48045c9",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "glm.0 <- glm (birthwt.below.2500 ~ . - birthwt.grams, data=birthwt.noout)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549ccc7b",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ccc9407",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(glm.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92fb4cc2",
      "metadata": {},
      "source": [
        "---\n",
        "### Generalized Linear Models\n",
        "The default value is a Gaussian model (a standard linear model). Change this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f8d69b",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "glm.1 <- glm (birthwt.below.2500 ~ . - birthwt.grams, data=birthwt.noout, family=binomial(link=logit))\n",
        "summary(glm.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15fbb685",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965fe565",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "par(mfrow = c(2,2))\n",
        "plot(glm.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f5d43c7",
      "metadata": {},
      "source": [
        "---\n",
        "### What Do We Do With This, Anyway?\n",
        "\n",
        "Let's take a subset of this data to do predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20fef9f4",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "odds <- seq(1, nrow(birthwt.noout), by=2)\n",
        "birthwt.in <- birthwt.noout[odds,]\n",
        "birthwt.out <- birthwt.noout[-odds,]\n",
        "linear.model.half <- lm (birthwt.grams ~ . - birthwt.below.2500, data=birthwt.in)\n",
        "summary (linear.model.half)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ea826f",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda91ba5",
      "metadata": {},
      "outputs": [],
      "source": [
        "birthwt.predict <- predict (linear.model.half)\n",
        "cor (birthwt.in$birthwt.grams, birthwt.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cdedc24",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "tibble(x = birthwt.out$birthwt.grams, y = birthwt.predict) |>\n",
        "  ggplot (aes(x = x, y = y)) + geom_point()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab22840",
      "metadata": {},
      "source": [
        "---\n",
        "### What Do We Do With This, Anyway?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629a4015",
      "metadata": {},
      "outputs": [],
      "source": [
        "birthwt.predict.out <- predict (linear.model.half, birthwt.out)\n",
        "cor (birthwt.out$birthwt.grams, birthwt.predict.out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5f570c",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12,
        "lines_to_next_cell": 0,
        "tags": [
          "remove_input"
        ]
      },
      "outputs": [],
      "source": [
        "tibble(x = birthwt.out$birthwt.grams, y = birthwt.predict.out) |> \n",
        "ggplot (aes(x = x, y = y)) + geom_point()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e321667d",
      "metadata": {},
      "source": [
        "---\n",
        "## Random number generators\n",
        "\n",
        "- We made reference to random number generation without going under the hood.\n",
        "- How _does_ R get \"random\" numbers? \n",
        "- It doesn't, really -- it uses a trick that should be indistinguishable from the real McCoy\n",
        "\n",
        "Pseudorandom generators produce a deterministic sequence that is indistiguishable from a true random sequence if you don't know how it started.\n",
        "\n",
        "#### Example: `runif`, where we know where it started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231ffe3b",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "runif(1:10)\n",
        "set.seed(10)\n",
        "runif(1:10)\n",
        "set.seed(10)\n",
        "runif(1:10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a31d08",
      "metadata": {},
      "source": [
        "---\n",
        "### Basic version: Linear Congruential Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff9f107",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "seed <- 10\n",
        "new.random <- function (a=5, c=12, m=16) {\n",
        "  out <- (a*seed + c) %% m  \n",
        "  seed <<- out\n",
        "  return(out)\n",
        "}\n",
        "out.length <- 20\n",
        "variates <- rep (NA, out.length)\n",
        "for (kk in 1:out.length) variates[kk] <- new.random()\n",
        "variates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7238f0ac",
      "metadata": {},
      "source": [
        "---\n",
        "## Try again\n",
        "\n",
        "Period 8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1003381f",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "variates <- rep (NA, out.length)\n",
        "for (kk in 1:out.length) variates[kk] <- new.random(a=131, c=7, m=16)\n",
        "variates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a30a38b",
      "metadata": {},
      "source": [
        "---\n",
        "## Try again, again\n",
        "\n",
        "Period 16:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3453202",
      "metadata": {},
      "outputs": [],
      "source": [
        "variates <- rep (NA, out.length)\n",
        "for (kk in 1:out.length) variates[kk] <- new.random(a=129, c=7, m=16)\n",
        "variates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd733fd",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "## Try again, at last\n",
        "\n",
        "Numerical Recipes uses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de76e827",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "variates <- rep (NA, out.length)\n",
        "for (kk in 1:out.length) variates[kk] <- new.random(a=1664545, c=1013904223, m=2^32)\n",
        "variates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342acc1d",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### How To Distinguish Non-Randomness\n",
        "\n",
        "- We've covered period: if it's missing some values, it's distinguishable \n",
        "- Uniformity of distribution in the limitx\n",
        "- Autocorrelation\n",
        "- Dimensional distribution -- not a problem for 1-D distributions, but can be for 2+-D\n",
        "\n",
        "---\n",
        "### How does R get everything we need?\n",
        "\n",
        "A few distributions of interest:\n",
        "\n",
        "- Uniform(0,1)\n",
        "- Bernoulli(p)\n",
        "- Binomial(n,p)\n",
        "- Gaussian(0,1)\n",
        "- Exponential(1)\n",
        "- Gamma(a)\n",
        "\n",
        "---\n",
        "### In R: everything we need\n",
        "\n",
        "Suppose we were working with the Exponential distribution.\n",
        "\n",
        "- `rexp()` generates variates from the distribution.\n",
        "- `dexp()` gives the probability density function.\n",
        "- `pexp()` gives the cumulative distribution function.\n",
        "- `qexp()` gives the quantiles.\n",
        "---\n",
        "#### `dexp()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ddf2fa",
      "metadata": {
        "dpi": 300,
        "fig.height": 4,
        "fig.width": 10,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "dexp(0:5)\n",
        "this.range <- 0:50/5\n",
        "plot (this.range, dexp(this.range), ty=\"l\")\n",
        "lines (this.range, dexp(this.range, rate=0.5), col=\"red\")\n",
        "lines (this.range, dexp(this.range, rate=0.2), col=\"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c41d000",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "#### `pexp()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9984b228",
      "metadata": {
        "dpi": 300,
        "fig.height": 4,
        "fig.width": 10,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "pexp(0:5)\n",
        "this.range <- 0:50/5\n",
        "plot (this.range, pexp(this.range), ty=\"l\")\n",
        "lines (this.range, pexp(this.range, rate=0.5), col=\"red\")\n",
        "lines (this.range, pexp(this.range, rate=0.2), col=\"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354fac22",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "#### `qexp()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2e1c95",
      "metadata": {
        "dpi": 300,
        "fig.height": 4,
        "fig.width": 10,
        "message": false
      },
      "outputs": [],
      "source": [
        "qexp(0:5)\n",
        "this.range <- seq(0,1,by=0.01)\n",
        "plot (this.range, qexp(this.range), ylim = c(0, 10), ty=\"l\")\n",
        "lines (this.range, qexp(this.range, rate=0.5), col=\"red\")\n",
        "lines (this.range, qexp(this.range, rate=0.2), col=\"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d79fdb",
      "metadata": {},
      "source": [
        "## Probability distributions\n",
        "- Distributions from data\n",
        "- Review of R for theoretical distributions\n",
        "- Fitting distributions to data\n",
        "- Checking distributions against data\n",
        "\n",
        "#### Let's Load Some Cheerful Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d5b541",
      "metadata": {
        "lines_to_next_cell": 0,
        "message": false
      },
      "outputs": [],
      "source": [
        "data(\"cats\", package=\"MASS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc14267",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "#### Let's Grab some Data\n",
        "\n",
        "The Standard and Poor's 500, or simply the S\\&P 500, is a stock market index tracking the stock performance of 500 large companies listed on exchanges in the United States. It is one of the most commonly followed equity indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1a64716",
      "metadata": {
        "message": false
      },
      "outputs": [],
      "source": [
        "library(readxl)\n",
        "SP <- read_excel(\"data/Stock_Bond.xls\") |> dplyr::select(Date, `S&P_AC`) |>\n",
        "  rename(Index = `S&P_AC`)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b10a70",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a5b43cd",
      "metadata": {
        "dpi": 300,
        "fig.height": 8,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "SP |> ggplot(aes(x = Date, y = Index)) + geom_line()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12a202b",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Let's Transform Some Data\n",
        "\n",
        "The price $p_t$ doesn't matter, what matters are the returns $r_t = \\log{(p_t/p_{t-1})}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a7c94b",
      "metadata": {
        "dpi": 300,
        "fig.height": 5,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "returns <- na.omit(as.vector(diff(log(SP$Index))))\n",
        "summary(returns)\n",
        "plot(returns, type=\"l\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3fc73a",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### The Data's Distribution\n",
        "`quantile(x,probs)` calculates the quantiles at `probs` from `x`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5646eb9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "quantile(returns,c(0.25,0.5,0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b72398",
      "metadata": {},
      "source": [
        "`ecdf()` - _e_ mpirical _c_ umulative _d_ istribution _f_ unction; no assumptions but also no guess about distribution between the observations\n",
        "\n",
        "In math, ECDF is often written as $\\widehat{F}$ or $\\widehat{F}_n$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a1b44b",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "plot(ecdf(returns), main=\"Empirical CDF of S&P 500 index returns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10a38b1f",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "<small>Conceptually, `quantile` and `ecdf` are inverses to each other</small>\n",
        "---\n",
        "### Getting Probability Densities from Data\n",
        "\n",
        "`hist(x)` calculates a histogram from x\n",
        "- divide the data range up into equal-width bins and _count_ how many fall into each bin\n",
        "- _Or_ divide bin counts by (total count)*(width of bin), and get an estimate of the probability density function (pdf)  \n",
        "<small>Produces plot as a default side-effect</small>\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89d7652",
      "metadata": {
        "dpi": 300,
        "fig.height": 8,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "hist(returns,n=101,probability=TRUE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc56414",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Probability Densities from Data (cont'd.)\n",
        "\n",
        "`density(x)` estimates the density of `x` by counting how many observations fall in a little window around each point, and then smoothing  \n",
        "    <small>\"Bandwidth\" $\\approx$ width of window around each point</small>  \n",
        "    <small>Technically, a \"kernel density estimate\"</small>  \n",
        "\n",
        "Remember: `density()` is an _estimate_ of the pdf, not The Truth\n",
        "\n",
        "`density` returns a collection of $x,y$ values, suitable for plotting\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9b0dec",
      "metadata": {
        "dpi": 300,
        "fig.height": 8,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "plot(density(returns),main=\"Estimated pdf of S&P 500 index  returns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7905f1b",
      "metadata": {},
      "source": [
        "---\n",
        "### Probability Densities from Data (cont'd.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf613c47",
      "metadata": {
        "dpi": 300,
        "fig.height": 8,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "hist(returns,n=101,probability=TRUE)\n",
        "lines(density(returns),lty=\"dashed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8314adce",
      "metadata": {},
      "source": [
        "---\n",
        "### Getting distributions from data (cont'd.)\n",
        "\n",
        "`table()` - tabulate outcomes, most useful for discrete spaces; remember to normalize if you want probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ff9630",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "plot(table(cats$Sex)/nrow(cats),ylab=\"probability\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6982e1a3",
      "metadata": {},
      "source": [
        "---\n",
        "### Who Cares About the Distribution of the Data?\n",
        "\n",
        "- Overly detailed: every single observation recorded as a separate tick\n",
        "    + _Too much information_\n",
        "- The exact set of samples would never repeat if we re-ran things anyway\n",
        "    + _That information is wrong_\n",
        "- Try to _summarize_ what will _generalize_ to other situations\n",
        "    + Use a model, remember the model's parameters\n",
        "    \n",
        "---\n",
        "### R commands for distributions\n",
        "\n",
        "- `d`_foo_ = the probability _d_ ensity (if continuous) or probability mass function of _foo_ (pdf or pmf)\n",
        "- `p`_foo_ = the cumulative _p_ robability function (CDF)\n",
        "- `q`_foo_ = the _q_ uantile function (inverse to CDF)\n",
        "- `r`_foo_ = draw _r_ andom numbers from `foo` (first argument always the number of draws)\n",
        "\n",
        "`?Distributions` to see which distributions are built in\n",
        "\n",
        "If you write your own, follow the conventions\n",
        "---\n",
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05431aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "dnorm(x=c(-1,0,1),mean=1,sd=0.1)\n",
        "pnorm(q=c(2,-2)) # defaults to mean=0,sd=1\n",
        "dbinom(5,size=7,p=0.7,log=TRUE)\n",
        "qchisq(p=0.95,df=5)\n",
        "rt(n=4,df=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01f9da9",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "## Displaying Probability Distributions\n",
        "\n",
        "`curve` is very useful for the `d`, `p`, `q` functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aee6fabb",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "curve(dgamma(x,shape=45,scale=1.9),from=0,to=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c4ebd3",
      "metadata": {},
      "source": [
        "---\n",
        "### How Do We Fit Distributional Models to the Data?\n",
        "\n",
        "- Match moments (mean, variance, etc.)\n",
        "- Match other summary statistics\n",
        "- Maximize the likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf80a97e",
      "metadata": {},
      "source": [
        "#### Method of Moments (MM), Closed Form\n",
        "\n",
        "- Pick enough moments that they **identify** the parameters\n",
        "    + At least 1 moment per parameter; algebraically independent\n",
        "- Write equations for the moments in terms of the parameters  \n",
        "e.g., for gamma\n",
        "\n",
        "$$\\mu = as ~,~ \\sigma^2 = as^2$$\n",
        "- Do the algebra by hand to solve the equations\n",
        "\n",
        "$$a=\\mu^2/\\sigma^2 ~,~ s = \\sigma^2/\\mu$$\n",
        "- Code up the formulas (did this in lab 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "817d3286",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "gamma.est_MM <- function(x) {\n",
        "  m <- mean(x); v <- var(x)\n",
        "  return(c(shape=m^2/v, scale=v/m))\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370d3719",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### MM, Numerically\n",
        "\n",
        "- Write functions to get moments from parameters (usually algebra)\n",
        "- Set up the difference between data and model as another function\n",
        "\n",
        "```\n",
        "gamma.mean <- function(shape,scale) { return(shape*scale) }\n",
        "gamma.var <- function(shape,scale) { return(shape*scale^2) }\n",
        "gamma.discrepancy <- function(shape,scale,x) {\n",
        "  return((mean(x)-gamma.mean(shape,scale))^2 + (var(x)-gamma.mean(shape,scale))^2)\n",
        "}\n",
        "```\n",
        "\n",
        "- Minimize it\n",
        "---\n",
        "### More Generally...\n",
        "\n",
        "- Nothing magic about moments\n",
        "- Match other data summaries, say the median\n",
        "    + Or even more complicated things, like ratios of quantiles  \n",
        "    + <small>You did this in lab</small>\n",
        "- If you can't solve exactly for parameters from the summaries, set up a discrepancy function and minimize it\n",
        "    + <small>You are doing this in the HW</small>\n",
        "- The summaries just have to converge on population values\n",
        "\n",
        "---\n",
        "\n",
        "### Maximum Likeihood\n",
        "\n",
        "- Usually we think of the parameters as fixed and consider the probability of different outcomes, $f(x;\\theta)$ with $\\theta$ constant and $x$ changing\n",
        "- **Likelihood** of a parameter value = $L(\\theta)$ = what probability does $\\theta$ give to the data?\n",
        "    + For continuous variables, use probability density\n",
        "    + $f(x;\\theta)$ but letting $\\theta$ change while data constant\n",
        "    + _Not_ the probability of $\\theta$, if that even makes sense\n",
        "- **Maximum likelihood** = guess that the parameter is whatever makes the data most likely\n",
        "- Most likely parameter value = **maximum likelihood estimate** = **MLE**\n",
        "\n",
        "---\n",
        "### Likelihood in Code\n",
        "\n",
        "- With independent data points $x_1, x_2, x_n$, likelihood is\n",
        "\n",
        "$$L(\\theta) = \\prod_{i=1}^{n}{f(x_i;\\theta)}$$\n",
        "- Multiplying lots of small numbers is numerically bad; take the log:\n",
        "\n",
        "$$\\ell(\\theta) = \\sum_{i=1}^{n}{\\log{f(x_i;\\theta)}}$$\n",
        "- In pseudo-code:\n",
        "\n",
        "```\n",
        "loglike.foo <- function(params, x) {\n",
        "  sum(dfoo(x=x,params,log=TRUE))\n",
        "}\n",
        "```\n",
        "---\n",
        "### What Do We Do with the Likelihood?\n",
        "\n",
        "- We maximize it!\n",
        "- Sometimes we can do the maximization by hand with some calculus\n",
        "    + For Gaussian, MLE = just match the mean and variance\n",
        "    + For Pareto, MLE $\\widehat{a} = 1 + 1/\\overline{\\log{(x/x_{\\mathrm{min}})}}$\n",
        "- Doing numerical optimization\n",
        "    + Stick in a minus sign if we're using a minimization function\n",
        "    \n",
        "---\n",
        "### Why Use the MLE?\n",
        "\n",
        "- Usually (but not always) _consistent_: converges on the truth as we get more data\n",
        "- Usually (but not always) _efficient_: converges on the truth at least as fast as anything else\n",
        "\n",
        "- There are some parameters where the maximum isn't well-defined (e.g. $x_{\\mathrm{min}}$ for a Pareto)\n",
        "- Sometimes the data is too aggregated or mangled to use the MLE (as with the income data in lab 5)\n",
        "\n",
        "---\n",
        "### fitdistr\n",
        "\n",
        "MLE for one-dimensional distributions can be done through `fitdistr` in the `MASS` package\n",
        "\n",
        "It knows about most the standard distributions, but you can also give it arbitrary probability density functions and it will try to maximize them  \n",
        "A starting value for the optimization is optional for some distributions, required for others (including user-defined densities)\n",
        "\n",
        "Returns the parameter estimates and standard errors  \n",
        "SEs come from large $n$ approximations so use cautiously\n",
        "\n",
        "---\n",
        "### fitdistr Examples\n",
        "\n",
        "Fit the gamma distribution to the cats' hearts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e48c9b83",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "require(MASS)\n",
        "fitdistr(cats$Hwt, densfun=\"gamma\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc02415e",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "Returns: estimates above, standard errors below\n",
        "\n",
        "Fit the Students $t$ distribution to the returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a319a214",
      "metadata": {
        "lines_to_next_cell": 0,
        "message": false,
        "warning": false
      },
      "outputs": [],
      "source": [
        "fitdistr(returns,\"t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d167c20",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "Here parameters are location (m), scale (s) and degrees of freedom (very heavy tails)\n",
        "\n",
        "---\n",
        "### fitdistr Examples (cont'd.)\n",
        "\n",
        "User-defined density:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b491a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "dpareto <- function(x,exponent,xmin,log=FALSE) {\n",
        "  f <- (exponent-1)/xmin * (x/xmin)^(-exponent)\n",
        "  f <- ifelse(x<xmin,NA,f)\n",
        "  if(!log) { return(f) } else (return(log(f)))\n",
        "}\n",
        "# Fit pareto to large absolute returns\n",
        "  # Parameters given outside the \"start\" list are fixed\n",
        "fitdistr(abs(returns)[abs(returns)>0.05], densfun=dpareto,\n",
        "         start=list(exponent=2.5), xmin=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24c330dd",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Checking Your Estimator\n",
        "\n",
        "- simulate, then estimate; estimates should converge as the sample grows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c08e67",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "gamma.est_MM(rgamma(100,shape=19,scale=45))\n",
        "gamma.est_MM(rgamma(1e5,shape=19,scale=45))\n",
        "gamma.est_MM(rgamma(1e6,shape=19,scale=45))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192135f0",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Checking the Fit\n",
        "\n",
        "_Use your eyes_: Graphic overlays of theory vs. data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b6c7c1b",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "plot(density(cats$Hwt))\n",
        "cats.gamma <- gamma.est_MM(cats$Hwt)\n",
        "curve(dgamma(x,shape=cats.gamma[\"shape\"],scale=cats.gamma[\"scale\"]),add=TRUE,col=\"blue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e469f02",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Checking the Fit (cont'd.)\n",
        "\n",
        "- Calculate summary statistics _not_ used in fitting, compare them to the fitted model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0bb4705",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "# Really bad and good days for index fund holders, per model:\n",
        "qnorm(c(0.01,0.99),mean=mean(returns),sd=sd(returns))\n",
        "# As it happened:\n",
        "quantile(returns,c(0.01,0.99)) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "547a38c0",
      "metadata": {},
      "source": [
        "---\n",
        "### Quantile-Quantile (QQ) Plots\n",
        "\n",
        "- Plot theoretical vs. actual quantiles\n",
        "- _or_ plot quantiles of two samples against each other\n",
        "- Ideally, a straight line when the distributions are the same\n",
        "- `qqnorm`, `qqline` are specialized for checking normality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1f63eb",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "qqnorm(returns); qqline(returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7804a77c",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### QQ Plots (cont'd)\n",
        "\n",
        "- `qqplot(x,y)` will do a Q-Q plot of one vector against another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed5c2c9",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12
      },
      "outputs": [],
      "source": [
        "qqplot(returns,qt((1:500)/501,df=3.59))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cdbc0b6",
      "metadata": {},
      "source": [
        "---\n",
        "### Calibration Plots\n",
        "\n",
        "- If the distribution is right, 50% of the data should be below the median, 90% should be below the 90th percentile, etc.\n",
        "- Special case of **calibration** of probabilities: events with probability _p_% should happen about _p_% of the time, not more and not less\n",
        "- We can look at calibraton by calculating the (empirical) CDF of the (theoretical) CDF and plotting\n",
        "    + Ideal calibration plot is a straight line up the diagonal\n",
        "    + Systematic deviations are a warning sign\n",
        "    \n",
        "---\n",
        "### Making a Calibration Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8b6fc0",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "plot(ecdf(pnorm(returns, mean=mean(returns), sd=sd(returns))),\n",
        "     main=\"Calibration of Gaussian distribution for returns\")\n",
        "abline(0,1,col=\"grey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a473c4a7",
      "metadata": {},
      "source": [
        "Again, way too many large changes (in either direction)\n",
        "\n",
        "---\n",
        "### Calibration Plots (cont'd.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763484e7",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12,
        "message": false,
        "warning": false
      },
      "outputs": [],
      "source": [
        "SP.t <- coefficients(fitdistr(returns,\"t\"))\n",
        "plot(ecdf(pt((returns-SP.t[1])/SP.t[2], df=SP.t[3])),\n",
        "     main=\"Calibration of t distribution for returns\")\n",
        "abline(0,1,col=\"grey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c48b41f",
      "metadata": {},
      "source": [
        "---\n",
        "### Calibration Plots (cont'd.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da612a31",
      "metadata": {
        "dpi": 300,
        "fig.height": 7,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "plot(ecdf(pgamma(cats$Hwt, shape=cats.gamma[\"shape\"], scale=cats.gamma[\"scale\"])),\n",
        "     main=\"Calibration of gamma distribution for cats' hearts\")\n",
        "abline(0,1,col=\"grey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b754bd8c",
      "metadata": {},
      "source": [
        "---\n",
        "### Calibration Plots (cont'd.)\n",
        "\n",
        "_Challenge_: Write a general function for making a calibraton plot, taking a\n",
        "data vector, a cumulative probability function, and a parameter vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d49675f",
      "metadata": {},
      "source": [
        "#### Kolmogorov-Smirnov Test\n",
        "\n",
        "- How much should the QQ plot or calibration plot wiggle around the diagonal?\n",
        "- Answer a different question...\n",
        "- Biggest gap between theoretical and empirical CDF:\n",
        "\n",
        "$$D_{KS} = \\max_{x}{\\left|F(x)-\\widehat{F}(x)\\right|}$$\n",
        "\n",
        "- Useful because $D_{KS}$ always has the same distribution _if_ the theoretical CDF is fixed and correct, and K+S calculated this back in the day\n",
        "- Also works for comparing the empirical CDFs of two samples, to see if they came from the same distribution\n",
        "\n",
        "---\n",
        "### KS Test, Data vs. Theory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75643079",
      "metadata": {
        "lines_to_next_cell": 0,
        "warning": false
      },
      "outputs": [],
      "source": [
        "ks.test(returns,pnorm,mean=0,sd=0.0125)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e6b4df",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "- More complicated (and _not_ properly handled by built-in R) if parameters are estimated\n",
        "    + Estimating parameters makes the fit look _better_ than it really is, so it doesn't help save the model when it gets really rejected (like this one is)\n",
        "\n",
        "Hack: Estimate using (say) 90% of the data, and then check the fit on the remaining 10%\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da66767",
      "metadata": {
        "warning": false
      },
      "outputs": [],
      "source": [
        "train <- sample(1:length(returns),size=round(0.9*length(returns)))\n",
        "SP.t_train <- coefficients(fitdistr(returns[train],\"t\"))\n",
        "returns.test_standardized <- (returns[-train]-SP.t_train[1])/SP.t_train[2]\n",
        "ks.test(returns.test_standardized,pt,df=SP.t_train[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ff56bd9",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "- Can also test whether two samples come from same distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ed1e0f",
      "metadata": {
        "lines_to_next_cell": 0,
        "warning": false
      },
      "outputs": [],
      "source": [
        "n <- length(returns)\n",
        "half <- round(n/2)\n",
        "ks.test(returns[1:half], returns[(half+1):n])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d3799b5",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Chi-Squared Test for Discrete Distributions\n",
        "\n",
        "Compare an actual table of counts to a hypothesized probability distribution\n",
        "\n",
        "e.g., as many up days as down?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c3c4ed4",
      "metadata": {
        "warning": false
      },
      "outputs": [],
      "source": [
        "up_or_down <- ifelse(returns > 0, 1, -1)\n",
        "# 1936 down days, 1772 up days\n",
        "chisq.test(table(up_or_down),p=c(1/2,1/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74cdfce1",
      "metadata": {},
      "source": [
        "#### Chi-Squared Test: Degrees of Freedom\n",
        "\n",
        "- The $p$-value calculated by `chisq.test` assumes that all the probabilities in $p$ were _fixed_, not estimated from the data used for testing, so `df =` number of cells in the table $-1$\n",
        "- If we estimate $q$ parameters, we need to subtract $q$ degrees of freedom\n",
        "---\n",
        "### Chi-Squared Test for Continuous Distributions\n",
        "\n",
        "- Divide the range into bins and count the number of observations in each bin; this will be `x` in `chisq.test()`\n",
        "- Use the CDF function `p` _foo_ to calculate the theoretical probability of each bin; this is `p`\n",
        "- Plug in to `chisq.test`\n",
        "- If parameters are estimated, adjust\n",
        "\n",
        "- `hist()` gives us break points and counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf12f1b6",
      "metadata": {
        "dpi": 300,
        "fig.height": 6,
        "fig.width": 12,
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "cats.hist <- hist(cats$Hwt,plot=FALSE)\n",
        "cats.hist$breaks\n",
        "cats.hist$counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1654991d",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "### Chi-Squared for Continuous Data (cont'd.)\n",
        "\n",
        "Use these for a $\\chi^2$ test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4ebac6",
      "metadata": {
        "lines_to_next_cell": 0,
        "warning": false
      },
      "outputs": [],
      "source": [
        "# Why the padding by -Inf and Inf?\n",
        "p <- diff(pgamma(c(-Inf,cats.hist$breaks,Inf),shape=cats.gamma[\"shape\"],\n",
        "                 scale=cats.gamma[\"scale\"]))\n",
        "# Why the padding by 0 and 0?\n",
        "x2 <- chisq.test(c(0,cats.hist$counts,0),p=p)$statistic\n",
        "# Why +2? Why -length(cats.gamma)?\n",
        "pchisq(x2,df=length(cats.hist$counts)+2 - length(cats.gamma))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7921aa26",
      "metadata": {},
      "source": [
        "Don't need to run `hist` first; can also use `cut` to discretize (see `?cut`)\n",
        "\n",
        "- This is all a bit old-school\n",
        "    + Loss of information from discretization\n",
        "    + Lots of work just to use $\\chi^2$\n",
        "- Try e.g. `ks.test` with an independent test set\n",
        "\n",
        "---\n",
        "### Summary\n",
        "\n",
        "- Visualizing and computing empirical distribution\n",
        "- Parametric distributions are models\n",
        "- Methods of fitting: moments, generalized moments, likelihood\n",
        "- Methods of checking: visual comparisons, other statistics, tests, calibration\n",
        "\n",
        "---\n",
        "### Aside: Some Math for MM and GMM\n",
        "\n",
        "- Parameter $\\theta$ is a $p$-dimensional vector, true value = $\\theta^*$\n",
        "- Introduce $q \\geq p$ **functionals** $g_1, \\ldots g_q$, which we can calculate either from the parameter $\\theta$ or from the data $x_{1:n}$\n",
        "- _Assume_ that for each $i$, $g_i(x_{1:n}) \\rightarrow g_i(\\theta^*)$\n",
        "- _Define_\n",
        "\n",
        "$$\\widehat{\\theta}_{GMM} = \\mathrm{argmin}_{\\theta}{\\sum_{i=1}^{q}{(g_i(\\theta) - g_i(x_{1:n}))^2}}$$\n",
        "\n",
        "---\n",
        "### Math for MM and GMM (cont'd.)\n",
        "\n",
        "- Shouldn't be hard to believe that $\\widehat{\\theta}_{GMM} \\rightarrow \\theta^*$\n",
        "- But why give equal attention to every functional?\n",
        "    + More weight on the more-precisely-measured functionals\n",
        "    + More weight on the more-sensitive-to $\\theta$ functionals\n",
        "    + Less weight on partially-redundant functionals\n",
        "-  _Abbreviate_ $g(\\theta)$ for $(g_1(\\theta), \\ldots g_q(\\theta))$, and likewise $g(x_{1:n})$, so\n",
        "\n",
        "$$\\widehat{\\theta}_{GMM} = \\mathrm{argmin}_{\\theta}{(g(\\theta)-g(x_{1:n}))^T(g(\\theta)-g(x_{1:n}))}$$\n",
        "\n",
        "- Generalize by introducing any positive-definite matrix $\\Omega$:\n",
        "\n",
        "$$\\widehat{\\theta}_{GMM} = \\mathrm{argmin}_{\\theta}{(g(\\theta)-g(x_{1:n}))^T \\Omega (g(\\theta)-g(x_{1:n}))}$$\n",
        "\n",
        "- Optimal $\\Omega$ turns out to be the variance matrix of $g(\\theta^*)$\n",
        "- Iterative approximation: start with no weighting, estimate that variance matrix, re-do the estimate with weights, etc.\n",
        "\n",
        "---\n",
        "### Aside: Some Math for the MLE\n",
        "\n",
        "- More convenient to work with the mean log likelihood:\n",
        "\n",
        "$$\\Lambda(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}{\\log{f(X_i;\\theta)}}$$\n",
        "\n",
        "- This is a sample average so the law of large numbers applies:\n",
        "\n",
        "$$\\Lambda(\\theta) \\rightarrow \\mathbf{E}[\\Lambda(\\theta)] = \\lambda(\\theta)$$\n",
        "\n",
        "- The true parameter has higher average log-likelihood than anything else: if $\\theta \\neq \\theta^*$\n",
        "\n",
        "$$\\theta \\neq \\theta^* ~ \\Rightarrow \\lambda(\\theta) < \\lambda(\\theta^*)$$\n",
        "\n",
        "- Some extra conditions are needed for\n",
        "\n",
        "$$\\widehat{\\theta}_{MLE} \\rightarrow \\theta^*$$\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "warning,name,message,dpi,out.width,fig.height,fig.width,tags,-all",
      "main_language": "R",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}